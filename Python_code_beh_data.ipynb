{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d2c848-6cbd-4505-a0a4-81a33f08a5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib\n",
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install scipy\n",
    "!pip install scikit-learn\n",
    "!pip install statsmodels\n",
    "!pip install seaborn\n",
    "!pip install numpy-indexed\n",
    "!pip install pingouin\n",
    "!pip install ggpubr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740512bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import scipy\n",
    "import numpy.matlib\n",
    "\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "sns.set_theme(style=\"ticks\", color_codes=True)\n",
    "import glob\n",
    "\n",
    "!pip install numpy-indexed\n",
    "import numpy_indexed as npi\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd6167d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get CSV files list \n",
    "\n",
    "csvFilenamesList = glob.glob('*LinearPI_MainTaskLog.csv')\n",
    "csvFilenamesList.sort()\n",
    "\n",
    "csvFilenamesList.pop(0) # remove the first one  sub-00- from the previous pilot\n",
    "print(len(csvFilenamesList))\n",
    "\n",
    "csvFilenamesList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9199f66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read each CSV file into DataFrame. This creates a list of dataframes\n",
    "\n",
    "df_list=[]\n",
    "for f in csvFilenamesList:\n",
    "    temp_df = pd.read_csv(f, sep=None, engine='python')\n",
    "    temp_df\n",
    "    df_list.append (temp_df)\n",
    "    \n",
    "mean_dist = round(np.mean(df_list[1]['mainMeters'].unique()), 2)\n",
    "mean_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8666908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing the distance estimation error and its absolute value\n",
    "df_list_ext=[]\n",
    "for df in df_list:\n",
    "    df_temp = df.assign(est_error=lambda x: (x.mainEstimate-x.mainMeters))\n",
    "    df_temp = df_temp.assign(abs_est_error=lambda x: abs(x.mainEstimate-x.mainMeters))\n",
    "    df_temp = df_temp.assign(center_dist=lambda x: abs(x.mainEstimate-mean_dist))\n",
    "    df_list_ext.append(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be80f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the missed trials and removing them from the data frames of each participant\n",
    "\n",
    "nSubjects=len(df_list_ext)\n",
    "missedTrials=np.zeros((nSubjects,1))\n",
    "\n",
    "df_no_missed_list = []\n",
    "for df in df_list_ext:\n",
    "    print(len(df))\n",
    "    df_no_missed = df[df['mainEstimate'] != -1].copy()\n",
    "    df_no_missed_list.append(df_no_missed)\n",
    "    print(len(df_no_missed))\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ee76d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the range of real distances for each participant\n",
    "main_dist = df_no_missed_list[1]['mainMeters'].unique()\n",
    "print('Main Meters =', main_dist)\n",
    "\n",
    "trial_duration = df_no_missed_list[1]['mainDuration'].unique()\n",
    "print('Main Duration = ', trial_duration)\n",
    "duration_min = np.min(trial_duration)\n",
    "duration_max = np.max(trial_duration)\n",
    "print(duration_min, duration_max)\n",
    "\n",
    "speed_level=df_no_missed_list[1]['mainSpeed'].unique() \n",
    "print('Speed levels = ', speed_level)\n",
    "\n",
    "xAcc=df_no_missed_list[1]['mainAccelerationDuration'].unique()  \n",
    "xDec=df_no_missed_list[1]['mainDecelerationDuration'].unique()  \n",
    "accdec_dur=.5*(np.unique(xAcc)+numpy.unique(xDec));\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dce6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the catch trials \n",
    "\n",
    "df_no_missed_no_catch_list = []\n",
    "for df in df_no_missed_list:\n",
    "    df_no_missed_no_catch = df[(df['mainDuration'] != duration_min) & (df['mainDuration'] != duration_max)].copy()    \n",
    "    df_no_missed_no_catch_list.append(df_no_missed_no_catch)\n",
    "    print(len(df_no_missed_no_catch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7f3c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding IDs\n",
    "sn=1\n",
    "for df in df_no_missed_no_catch_list:\n",
    "    [a, b]=(df).shape\n",
    "    if sn < 10:\n",
    "        df[\"ID\"]=(['P0' + str(sn)]*a)\n",
    "    else:\n",
    "        df[\"ID\"]=(['P' + str(sn)]*a)\n",
    "    sn=sn+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab13a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatinating dfs\n",
    "df_concat=pd.concat(df_no_missed_no_catch_list)\n",
    "df_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6643f9ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plotting the regression fitted line for real vs. estimated distances for each ptp\n",
    "\n",
    "for df_temp in df_no_missed_no_catch_list:\n",
    "    X = df_temp.iloc[:,10].values.reshape(-1, 1)  # real distnces \n",
    "    Y = df_temp.iloc[:,9].values.reshape(-1, 1)  # estimated distances \n",
    "    linear_regressor = LinearRegression()\n",
    "    linear_regressor.fit(X, Y)\n",
    "    Y_pred = linear_regressor.predict(X)\n",
    "\n",
    "    plt.scatter(X, Y)\n",
    "    plt.plot(X, Y_pred, color='red', label='fitted line')\n",
    "    plt.plot(X, X, color='green', label='perfect estimate')\n",
    "    plt.legend(loc=\"upper left\")\n",
    "\n",
    "    plt.title(df_temp.iloc[1,21] , fontsize=15)\n",
    "    plt.xlabel(\"Real Distances\", fontsize=15)\n",
    "    plt.ylabel(\"Estimated Distances\", fontsize=15)\n",
    "    plt.xlim([100, 500])\n",
    "    plt.ylim([-20, 900])\n",
    "    plt.savefig('./Figures/' + 'regfit_estimations_' + df_temp.iloc[1,21] + '.png', bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce9d07a-24cb-472f-a455-4b9a09e220ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_temp.iloc[1,21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8966f2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the regression fitted line for estimation error for each ptp\n",
    "\n",
    "for df_temp in df_no_missed_no_catch_list:\n",
    "    X = df_temp.iloc[:,10].values.reshape(-1, 1)  # real distnces \n",
    "    Y = df_temp.iloc[:,18].values.reshape(-1, 1)  # estimation error \n",
    "    linear_regressor = LinearRegression()\n",
    "    linear_regressor.fit(X, Y)\n",
    "    Y_pred = linear_regressor.predict(X)\n",
    "\n",
    "    zeroY=np.zeros(len(X))\n",
    "    plt.scatter(X, Y)\n",
    "    plt.plot(X, Y_pred, color='red', label='fitted line')\n",
    "    plt.plot(X, zeroY, color='green', label='perfect estimate')\n",
    "    plt.legend(loc=\"upper left\")\n",
    "\n",
    "    plt.title(df_temp.iloc[1,21] , fontsize=15)\n",
    "    plt.xlabel(\"Real distances\", fontsize=15)\n",
    "    plt.ylabel(\"Estimation error\", fontsize=15)\n",
    "    plt.xlim([100, 500])\n",
    "    plt.ylim([-400, 400])\n",
    "    plt.savefig('./Figures/' + 'regfit_estimation_error_' + df_temp.iloc[1,21] + '.png', bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fbbfef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# estimation error across runs for all the participants\n",
    "\n",
    "ax=sns.pointplot(x='RunNumber', y=(df_concat.est_error), hue='ID', errorbar='sd', data=df_concat, \\\n",
    "                  order=[1, 2, 3, 4], dodge=False, linestyle='-', err_kws={'linewidth': 1}, palette=\"mako\")\n",
    "sns.set(font_scale = 1)\n",
    "plt.xlabel('run number', fontsize = 15)\n",
    "plt.ylabel('estimation error', fontsize = 15)\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
    "# ax2.get_legend().remove()\n",
    "sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 1), title='')\n",
    "plt.title('Estimation error across the runs \\n', fontsize = 18)\n",
    "plt.savefig('./Figures/'+'ErrorAcrossRuns_AllParticipants.png', bbox_inches = \"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3de9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by participant ID and condition, and compute the mean of each group\n",
    "\n",
    "# compute the mean of estimations for each real distance for each participant: df_mean\n",
    "df_mean = df_concat.groupby(['ID', 'mainMeters'])['mainEstimate'].mean().reset_index()\n",
    "\n",
    "sns.set_palette(\"rocket\")\n",
    "# Plot the fitted line for every subject without scatter plot points\n",
    "for subject_id in df_concat['ID'].unique():\n",
    "    subject_data = df_concat[df_concat['ID'] == subject_id]\n",
    "    sns.regplot(x='mainMeters', y='mainEstimate', data=subject_data, ci=None, scatter=False, line_kws={'alpha': 0.2})\n",
    "\n",
    "# Plot the fitted line to the data of all participants\n",
    "sns.regplot(x='mainMeters', y='mainEstimate', data=df_mean, ci=None, scatter=True, color='#6B007B', line_kws={'linewidth': 3})\n",
    "plt.legend([],[], frameon=False)\n",
    "plt.plot([100, 500], [100, 500],'k', linestyle='dashed', linewidth=1.5)\n",
    "\n",
    "sns.set(font_scale = 1)\n",
    "plt.xlabel('actual distances', fontsize = 16)\n",
    "plt.ylabel('estimated distances', fontsize = 16)\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
    "plt.title('Regression to the mean effect \\n', fontsize = 18)\n",
    "plt.tight_layout()\n",
    "plt.savefig('Figures/'+'estimated_distVreal_dist_across_group.png', bbox_inches = \"tight\", dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd719cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.pointplot(x='RunNumber', y='est_error', hue='mainSpeed', data=df_concat, order=[1, 2, 3, 4], dodge=False, err_kws={'linewidth': 1}, palette=\"mako\")\n",
    "sns.set(font_scale = 1)\n",
    "plt.xlabel('run', fontsize = 16)\n",
    "plt.ylabel('estimation error', fontsize = 16)\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
    "# ax2.get_legend().remove()\n",
    "sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 1), title='')\n",
    "plt.title('Estimation error across runs at each speed level', fontsize = 13)\n",
    "plt.savefig('Figures/'+'estimation_error_across_runs_based_speed.png', bbox_inches = \"tight\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574c9121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# effect of run number on distance estimation error across participants \n",
    "\n",
    "# Number of runs to analyze\n",
    "nRun = 4\n",
    "\n",
    "# Initialize a matrix to store mean absolute estimation errors for each subject and run\n",
    "error_mat = np.zeros((len(df_list_ext), nRun)) \n",
    "\n",
    "# Initialize a subject index\n",
    "sn = 0\n",
    "\n",
    "# Loop through each dataframe in the list\n",
    "for df in df_list_ext:  \n",
    "    # Create a copy of the current dataframe to avoid modifying the original\n",
    "    df_temp = df.copy()\n",
    "    \n",
    "    # Loop through each run\n",
    "    for iRun in range(nRun):  \n",
    "        # Initialize mean estimation error\n",
    "        meanEstimationError = 0\n",
    "        \n",
    "        # Filter the dataframe for the current run\n",
    "        df_run = df_temp.loc[df['RunNumber'] == iRun + 1]\n",
    "        \n",
    "        # Calculate the mean of the absolute estimation errors for the current run\n",
    "        meanEstimationError = np.mean(abs(df_run.abs_est_error))\n",
    "        \n",
    "        # Store the mean estimation error in the error matrix\n",
    "        error_mat[sn][iRun] = meanEstimationError\n",
    "    \n",
    "    # Increment the subject index for the next dataframe\n",
    "    sn = sn + 1\n",
    "\n",
    "# Create a run number array\n",
    "run_mat = np.array([1, 2, 3, 4])\n",
    "\n",
    "# Repeat the run numbers for each subject and flatten the result into a 1D array\n",
    "run_vec = np.matlib.repmat(run_mat, 1, len(df_list_ext))\n",
    "run_vec = run_vec.flatten()\n",
    "\n",
    "# Flatten the error matrix into a 1D array\n",
    "error_vec = error_mat.reshape(np.prod(error_mat.shape), 1)\n",
    "error_vec = error_vec.flatten()\n",
    "\n",
    "# Create a subjects vector, repeating each subject number for each run\n",
    "subjects_vec = np.repeat(np.arange(len(df_list_ext)) + 1, nRun)\n",
    "subjects_vec = subjects_vec.reshape(nRun * len(df_list_ext), 1)\n",
    "subjects_vec = subjects_vec.flatten()\n",
    "\n",
    "# Create a DataFrame for ANOVA analysis with subjects, run numbers, and errors\n",
    "df_run = pd.DataFrame({'Subjects': subjects_vec,\n",
    "                       'RunNumber': run_vec,\n",
    "                       'Error': error_vec}, index=np.arange(1, nRun * len(df_list_ext) + 1))\n",
    "\n",
    "# Print the DataFrame to check the structure\n",
    "print(df_run)\n",
    "\n",
    "# Perform repeated measures ANOVA on the error data\n",
    "print(AnovaRM(data=df_run, depvar='Error', subject='Subjects', within=['RunNumber']).fit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1111091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd  # For data manipulation and analysis\n",
    "import statsmodels.api as sm  # For statistical models\n",
    "from statsmodels.formula.api import ols, mixedlm  # For Ordinary Least Squares and Mixed Linear Models\n",
    "from statsmodels.stats.anova import AnovaRM  # For Repeated Measures ANOVA\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd  # For Tukey's HSD test\n",
    "from scipy.stats import ttest_rel, ttest_ind  # For paired and independent t-tests\n",
    "from statsmodels.stats.multitest import multipletests  # For multiple testing correction\n",
    "import pingouin as pg  # For statistical tests and data analysis\n",
    "\n",
    "# Group the data by participant (ID) and condition (mainMeters), and calculate the standard deviation of the response (est_error) for each group\n",
    "std_dev = df_concat.groupby(['ID', 'mainMeters'])['est_error'].std().reset_index()\n",
    "\n",
    "# Pivot the data to create a matrix of standard deviations, with participants as rows and conditions as columns\n",
    "std_dev_matrix = std_dev.pivot(index='ID', columns='mainMeters', values='est_error')\n",
    "\n",
    "# Set the color palette for the plots to \"rocket\"\n",
    "sns.set_palette(\"rocket\")\n",
    "\n",
    "# Create a violin plot to visualize the distribution of standard deviations of estimation errors by condition\n",
    "ax = sns.violinplot(x='mainMeters', y='est_error', data=std_dev)\n",
    "\n",
    "# Add point plot to the violin plot to show mean estimation errors with error bars representing standard deviation\n",
    "sns.pointplot(x='mainMeters', y='est_error', hue='ID', errorbar='sd', data=std_dev,\n",
    "              dodge=False, err_kws={'linewidth': 1}, linewidth=1, palette=\"rocket\", ax=ax)\n",
    "\n",
    "# Perform pairwise t-tests between conditions to assess differences in estimation errors\n",
    "pairwise_res = pg.pairwise_tests(data=std_dev, dv='est_error', within='mainMeters', subject='ID')\n",
    "\n",
    "# Loop through the results of pairwise tests to add significance indicators to the plot\n",
    "for i in range(len(pairwise_res)):\n",
    "    if pairwise_res['p-unc'][i] < 0.05:  # Check if the p-value is less than the significance level (0.05)\n",
    "        # Calculate the x-coordinates for the lines indicating significant differences\n",
    "        x_min = pairwise_res['A'][i]\n",
    "        x_min = (x_min - 120) / 120  # Normalize x_min for plotting\n",
    "        x_max = pairwise_res['B'][i]\n",
    "        x_max = (x_max - 120) / 120  # Normalize x_max for plotting\n",
    "        \n",
    "        # Set the y-coordinate for the significance line\n",
    "        y_line = 10 * i + 140\n",
    "        p_val = round(pairwise_res['p-unc'][i], 2)  # Round p-value for display\n",
    "        \n",
    "        # Draw a horizontal line to indicate significant differences\n",
    "        ax.hlines(y=y_line, xmin=x_min, xmax=x_max, color='k', linewidth=1)\n",
    "        \n",
    "        # Annotate the plot with the p-value\n",
    "        ax.annotate(\"p = {}\".format(p_val), xy=((x_min + x_max) * .5, y_line), \n",
    "                    ha='center', va='bottom', color='k', fontsize=10)\n",
    "\n",
    "# Remove top and right spines from the plot for better aesthetics\n",
    "sns.despine()\n",
    "\n",
    "# Set the limits and labels for the plot\n",
    "plt.title('Variance of estimation error increases \\n with distance \\n', fontsize=18)\n",
    "plt.xlabel('actual distances', fontsize=16)\n",
    "plt.ylabel('sd of estimation error', fontsize=16)\n",
    "\n",
    "# Remove legend labels for clarity\n",
    "ax.legend(labels=[])\n",
    "\n",
    "# Save the figure to a file with high resolution\n",
    "plt.savefig('./Figures/' + 'estimation_error_sd.png', bbox_inches=\"tight\", dpi=300)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "# perform a repeated measures ANOVA on the standard deviation of the response for each condition\n",
    "rm = AnovaRM(std_dev, 'est_error', 'ID', within=['mainMeters'])\n",
    "res = rm.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddf62c0-b19d-4b40-8e86-d4bc359e3822",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize lists to store the means for each half\n",
    "first_half_means = []\n",
    "second_half_means = []\n",
    "\n",
    "for df in df_no_missed_no_catch_list:\n",
    "    # Select run1 data\n",
    "    run1_data = df[df.iloc[:, 0] == 1]\n",
    "    \n",
    "    # Calculate the midpoint\n",
    "    midpoint = len(run1_data) // 2\n",
    "    \n",
    "    # Split the DataFrame and calculate means\n",
    "    first_half_mean = run1_data.iloc[:midpoint, 20].median()  # Column 21 is index 20\n",
    "    second_half_mean = run1_data.iloc[midpoint:, 20].median()\n",
    "    \n",
    "    first_half_means.append(first_half_mean)\n",
    "    second_half_means.append(second_half_mean)\n",
    "\n",
    "# Create a DataFrame for plotting\n",
    "plot_data = pd.DataFrame({\n",
    "    'Half': ['First Half'] * 29 + ['Second Half'] * 29,\n",
    "    'Mean': first_half_means + second_half_means\n",
    "})\n",
    "\n",
    "# Create the violin plot with individual data points\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.violinplot(x='Half', y='Mean', data=plot_data, inner=None)\n",
    "sns.swarmplot(x='Half', y='Mean', data=plot_data, color='black', size=5)\n",
    "\n",
    "# Add lines connecting dots from the same participants\n",
    "for i in range(len(first_half_means)):\n",
    "    plt.plot([0, 1], [first_half_means[i], second_half_means[i]], color='gray', alpha=0.3)\n",
    "    \n",
    "plt.title('Distribution of Means for First and Second Half of Run1 Data')\n",
    "plt.xlabel('Half of Run1 Data')\n",
    "plt.ylabel('Mean of Column 10')\n",
    "\n",
    "# Add some jitter to the swarm plot to reduce overlapping\n",
    "plt.xlim(-0.5, 1.5)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Assuming you have already created the first_half_means and second_half_means lists\n",
    "\n",
    "# Perform paired t-test\n",
    "t_statistic, p_value = stats.ttest_rel(first_half_means, second_half_means)\n",
    "\n",
    "# Calculate effect size (Cohen's d for paired samples)\n",
    "d = (np.mean(first_half_means) - np.mean(second_half_means)) / np.std(np.array(first_half_means) - np.array(second_half_means))\n",
    "\n",
    "# Print results\n",
    "print(f\"Paired t-test results:\")\n",
    "print(f\"t-statistic: {t_statistic}\")\n",
    "print(f\"p-value: {p_value}\")\n",
    "print(f\"Effect size (Cohen's d): {d}\")\n",
    "\n",
    "# Determine if the difference is significant (using alpha = 0.05)\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(f\"The difference between the two halves is statistically significant (p < {alpha}).\")\n",
    "else:\n",
    "    print(f\"The difference between the two halves is not statistically significant (p >= {alpha}).\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458a70f3-285b-4893-a29d-2d2870621fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean RT across runs\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd  # For data manipulation and analysis\n",
    "import statsmodels.api as sm  # For statistical models\n",
    "from statsmodels.formula.api import ols, mixedlm  # For Ordinary Least Squares and Mixed Linear Models\n",
    "from statsmodels.stats.anova import AnovaRM  # For Repeated Measures ANOVA\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd  # For Tukey's HSD test\n",
    "from scipy.stats import ttest_rel, ttest_ind  # For paired and independent t-tests\n",
    "from statsmodels.stats.multitest import multipletests  # For multiple testing correction\n",
    "import pingouin as pg  # For statistical tests and data analysis\n",
    "\n",
    "# Group the data by participant (ID) and condition (Run number), and calculate the mean of the response (RT) for each group\n",
    "mean_RT = df_concat.groupby(['ID', 'RunNumber'])['mainEstimateRT'].mean().reset_index()\n",
    "\n",
    "# Pivot the data to create a matrix of means, with participants as rows and conditions as columns\n",
    "# mean_RT_matrix = mean_RT.pivot(index='ID', columns='RunNumber', values='mainEstimateRT')\n",
    "\n",
    "# Set the color palette for the plots to \"rocket\"\n",
    "sns.set_palette(\"rocket\")\n",
    "\n",
    "# Create a violin plot to visualize the distribution of means of RTs by condition\n",
    "ax = sns.violinplot(x='RunNumber', y='mainEstimateRT', data=mean_RT)\n",
    "\n",
    "# Add point plot to the violin plot to show mean RT with error bars representing standard deviation\n",
    "sns.pointplot(x='RunNumber', y='mainEstimateRT', hue='ID', errorbar='sd', data=mean_RT,\n",
    "              dodge=False, err_kws={'linewidth': 1}, linewidth=1, palette=\"rocket\", ax=ax)\n",
    "\n",
    "# Perform pairwise t-tests between conditions to assess differences in RTs\n",
    "pairwise_res_mean_RT = pg.pairwise_tests(data=mean_RT, dv='mainEstimateRT', within='RunNumber', subject='ID')\n",
    "\n",
    "# # Loop through the results of pairwise tests to add significance indicators to the plot\n",
    "for i in range(len(pairwise_res_mean_RT)):\n",
    "    if pairwise_res_mean_RT['p-unc'][i] < 0.05:  # Check if the p-value is less than the significance level (0.05)\n",
    "        # Calculate the x-coordinates for the lines indicating significant differences\n",
    "        x_min = pairwise_res_mean_RT['A'][i]\n",
    "        x_min = (x_min - 1) / 1  # Normalize x_min for plotting\n",
    "        x_max = pairwise_res_mean_RT['B'][i]\n",
    "        x_max = (x_max - 1) / 1  # Normalize x_max for plotting\n",
    "        \n",
    "        # Set the y-coordinate for the significance line\n",
    "        y_line =  0.25*i + 6\n",
    "        p_val = round(pairwise_res_mean_RT['p-unc'][i], 2)  # Round p-value for display\n",
    "        \n",
    "        # Draw a horizontal line to indicate significant differences\n",
    "        ax.hlines(y=y_line, xmin=x_min, xmax=x_max, color='k', linewidth=1)\n",
    "        \n",
    "        # Annotate the plot with the p-value\n",
    "        ax.annotate(\"p = {}\".format(p_val), xy=((x_min + x_max) * .5, y_line), \n",
    "                    ha='center', va='bottom', color='k', fontsize=10)\n",
    "\n",
    "# Remove top and right spines from the plot for better aesthetics\n",
    "sns.despine()\n",
    "\n",
    "# Set the limits and labels for the plot\n",
    "plt.title('mean of RT across runs\\n', fontsize=18)\n",
    "plt.xlabel('run number', fontsize=16)\n",
    "plt.ylabel('mean RT', fontsize=16)\n",
    "\n",
    "# Remove legend labels for clarity\n",
    "ax.legend(labels=[])\n",
    "\n",
    "# Save the figure to a file with high resolution\n",
    "plt.savefig('./Figures/' + 'mean_RT_across_runs.png', bbox_inches=\"tight\", dpi=300)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "# perform a repeated measures ANOVA on the mean RT of the response for each condition\n",
    "rm_meanRT = AnovaRM(mean_RT, 'mainEstimateRT', 'ID', within=['RunNumber'])\n",
    "res_meanRT = rm_meanRT.fit()\n",
    "# print(res_meanRT.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe36bf84-d966-4b6f-8cf9-9324e2c50cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#oncet of RTs\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd  # For data manipulation and analysis\n",
    "import statsmodels.api as sm  # For statistical models\n",
    "from statsmodels.formula.api import ols, mixedlm  # For Ordinary Least Squares and Mixed Linear Models\n",
    "from statsmodels.stats.anova import AnovaRM  # For Repeated Measures ANOVA\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd  # For Tukey's HSD test\n",
    "from scipy.stats import ttest_rel, ttest_ind  # For paired and independent t-tests\n",
    "from statsmodels.stats.multitest import multipletests  # For multiple testing correction\n",
    "import pingouin as pg  # For statistical tests and data analysis\n",
    "\n",
    "# Group the data by participant (ID) and condition (Run number), and calculate the mean of the response (RT) for each group\n",
    "mean_RT = df_concat.groupby(['ID', 'RunNumber'])['reactionOnset'].mean().reset_index()\n",
    "\n",
    "# Pivot the data to create a matrix of means, with participants as rows and conditions as columns\n",
    "# mean_RT_matrix = mean_RT.pivot(index='ID', columns='RunNumber', values='mainEstimateRT')\n",
    "\n",
    "# Set the color palette for the plots to \"rocket\"\n",
    "sns.set_palette(\"rocket\")\n",
    "\n",
    "# Create a violin plot to visualize the distribution of means of RTs by condition\n",
    "ax = sns.violinplot(x='RunNumber', y='reactionOnset', data=mean_RT)\n",
    "\n",
    "# Add point plot to the violin plot to show mean RT with error bars representing standard deviation\n",
    "sns.pointplot(x='RunNumber', y='reactionOnset', hue='ID', errorbar='sd', data=mean_RT,\n",
    "              dodge=False, err_kws={'linewidth': 1}, linewidth=1, palette=\"rocket\", ax=ax)\n",
    "\n",
    "# Perform pairwise t-tests between conditions to assess differences in RTs\n",
    "pairwise_res_mean_RT = pg.pairwise_tests(data=mean_RT, dv='reactionOnset', within='RunNumber', subject='ID')\n",
    "\n",
    "# # Loop through the results of pairwise tests to add significance indicators to the plot\n",
    "for i in range(len(pairwise_res_mean_RT)):\n",
    "    if pairwise_res_mean_RT['p-unc'][i] < 0.05:  # Check if the p-value is less than the significance level (0.05)\n",
    "        # Calculate the x-coordinates for the lines indicating significant differences\n",
    "        x_min = pairwise_res_mean_RT['A'][i]\n",
    "        x_min = (x_min - 1) / 1  # Normalize x_min for plotting\n",
    "        x_max = pairwise_res_mean_RT['B'][i]\n",
    "        x_max = (x_max - 1) / 1  # Normalize x_max for plotting\n",
    "        \n",
    "        # Set the y-coordinate for the significance line\n",
    "        y_line =  0.25*i + 2.5\n",
    "        p_val = round(pairwise_res_mean_RT['p-unc'][i], 2)  # Round p-value for display\n",
    "        \n",
    "        # Draw a horizontal line to indicate significant differences\n",
    "        ax.hlines(y=y_line, xmin=x_min, xmax=x_max, color='k', linewidth=1)\n",
    "        \n",
    "        # Annotate the plot with the p-value\n",
    "        ax.annotate(\"p = {}\".format(p_val), xy=((x_min + x_max) * .5, y_line), \n",
    "                    ha='center', va='bottom', color='k', fontsize=10)\n",
    "\n",
    "# Remove top and right spines from the plot for better aesthetics\n",
    "sns.despine()\n",
    "\n",
    "# Set the limits and labels for the plot\n",
    "plt.title('onset of RT across runs\\n', fontsize=18)\n",
    "plt.xlabel('run number', fontsize=16)\n",
    "plt.ylabel('mean RT', fontsize=16)\n",
    "\n",
    "# Remove legend labels for clarity\n",
    "ax.legend(labels=[])\n",
    "\n",
    "# Save the figure to a file with high resolution\n",
    "plt.savefig('./Figures/' + 'onset_RT_across_runs.png', bbox_inches=\"tight\", dpi=300)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "# perform a repeated measures ANOVA on the mean RT of the response for each condition\n",
    "rm_meanRT = AnovaRM(mean_RT, 'reactionOnset', 'ID', within=['RunNumber'])\n",
    "res_meanRT = rm_meanRT.fit()\n",
    "print(res_meanRT.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f259f3e3-e888-402a-84b5-da66d52e8bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df_temp in df_no_missed_no_catch_list:\n",
    "    mean_value = np.mean(df_temp.iloc[0:23,11].values.reshape(-1, 1)).item()\n",
    "    \n",
    "    rvalues=(df_temp.iloc[0:23,11].values.reshape(-1, 1))\n",
    "    # rvalues.reshape(-1)\n",
    "    # print(*rvalues)\n",
    "    print(mean_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b594c9-d4a0-42be-9e0c-175b9e6dffca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for df_temp in df_no_missed_no_catch_list:\n",
    "mean_value = np.mean(df_no_missed_no_catch_list[1].iloc[:,20].values.reshape(-1, 1)).item()\n",
    "\n",
    "rvalues=(df_no_missed_no_catch_list[1].iloc[:,20].values.reshape(-1, 1))\n",
    "est_values=df_no_missed_no_catch_list[1].iloc[:,9].values.reshape(-1, 1)\n",
    "# rvalues.reshape(-1)\n",
    "print(*rvalues)\n",
    "print(*est_values)\n",
    "print(mean_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1042d085-9859-48f9-b22b-c4661dea99f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import mixedlm\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from scipy.stats import ttest_rel\n",
    "from scipy.stats import ttest_ind\n",
    "from statsmodels.stats.multitest import multipletests \n",
    "\n",
    "means_data = df_concat.groupby(['ID', 'RunNumber'])['est_error'].mean().reset_index()\n",
    "\n",
    "# set the color palette to \"rocket\"\n",
    "sns.set_palette(\"rocket\")\n",
    "\n",
    "ax=sns.violinplot(x='RunNumber', y='est_error', data=means_data, inner=None)\n",
    "\n",
    "# # add swarmplot points to the violin plot\n",
    "# sns.swarmplot(x='RunNumber', y='center_dist', data=means_data, hue='ID', palette='dark:white', edgecolor='auto', dodge=False, ax=ax)\n",
    "sns.pointplot(x='RunNumber', y='est_error', hue='ID', errorbar='sd', data=means_data, \\\n",
    "                   dodge=False, err_kws={'linewidth': 1}, linewidth=1, palette=\"mako\", ax=ax)\n",
    "\n",
    "plt.title('')\n",
    "plt.xlabel('run')\n",
    "plt.ylabel('estimation error')\n",
    "# ax.legend(loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "# deactivate the legend\n",
    "ax.legend(labels=[])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# perform a repeated measures ANOVA on the standard deviation of the response for each condition\n",
    "rm = AnovaRM(means_data, 'est_error', 'ID', within=['RunNumber'])\n",
    "res = rm.fit()\n",
    "print(res.summary())\n",
    "\n",
    "# add significance markers to the plot\n",
    "tukey_center_mean_results = pairwise_tukeyhsd(means_data['est_error'], means_data['RunNumber'], alpha=0.05)\n",
    "tukey_center_mean_results = pd.DataFrame(data=tukey_center_mean_results._results_table.data[1:], columns=tukey_center_mean_results._results_table.data[0])\n",
    "tukey_center_mean_results = tukey_center_mean_results[tukey_center_mean_results['reject'] == True]\n",
    "# y_values = [std_dev['CenterDist'].max()*1.1, std_dev['CenterDist'].max()*1.2, std_dev['CenterDist'].max()*1.3]\n",
    "\n",
    "\n",
    "print(tukey_center_mean_results)\n",
    "# for i, row in tukey_center_mean_results.iterrows():\n",
    "#     x1, x2 = std_dev['RunNumber'].unique().tolist().index(row['group1']), std_dev['RunNumber'].unique().tolist().index(row['group2'])\n",
    "#     y = y_values[i%3]\n",
    "#     pval = round(row['p-adj'], 3)\n",
    "#     ax.hlines(y=y, xmin=x1, xmax=x2, color='k', linewidth=1)\n",
    "#     ax.annotate(\"p = {}\".format(pval), xy=((x1+x2)*.5, y), ha='center', va='bottom', color='k', fontsize=10)\n",
    "\n",
    "\n",
    "# Perform pairwise t-tests between conditions\n",
    "pairwise_res = pg.pairwise_tests(data=means_data, dv='est_error', within='RunNumber', subject='ID')\n",
    "\n",
    "# Add significance indicators to the plot\n",
    "for i in range(len(pairwise_res)):\n",
    "    if pairwise_res['p-unc'][i] < 0.05:  # Adjust significance level as needed\n",
    "        x_min=pairwise_res['A'][i]\n",
    "        x_min=(x_min-120)/120\n",
    "        x_max=pairwise_res['B'][i]\n",
    "        x_max=(x_max-120)/120\n",
    "        y_line=10*i+140\n",
    "        p_val=round(pairwise_res['p-unc'][i], 2)\n",
    "        print(p_val)\n",
    "        # zero_line=np.zeros(len(xmax-xmin))\n",
    "        # sns.lineplot(x=[xmin, xmax], y=[4*i+120, 4*i+120], color='m', label=round(pairwise_res['p-unc'][i],2), linestyle='--', ax=ax)\n",
    "\n",
    "        # ax.hlines(y=y_line, xmin=x_min, xmax=x_max, color='k', linewidth=1)\n",
    "        # ax.annotate(\"p = {}\".format(p_val), xy=((x_min+x_max)*.5, y_line), ha='center', va='bottom', color='k', fontsize=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18f6076",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "std_center_data = df_concat.groupby(['ID', 'RunNumber'])['CenterDist'].std().reset_index()\n",
    "\n",
    "# set the color palette to \"rocket\"\n",
    "sns.set_palette(\"rocket\")\n",
    "\n",
    "ax=sns.violinplot(x='RunNumber', y='CenterDist', data=std_center_data)\n",
    "\n",
    "# add swarmplot points to the violin plot\n",
    "sns.swarmplot(x='RunNumber', y='CenterDist', data=std_center_data, hue='ID', color='white', edgecolor='gray', ax=ax)\n",
    "\n",
    "\n",
    "plt.xlabel('Run')\n",
    "plt.ylabel('SD response distance from the center')\n",
    "# plt.title('Participant Response Across Runs')\n",
    "# plt.legend(title='Participant')\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "# deactivate the legend\n",
    "ax.legend(labels=[])\n",
    "plt.show()\n",
    "\n",
    "# perform a repeated measures ANOVA on the standard deviation of the response for each condition\n",
    "rm_sd = AnovaRM(std_center_data, 'CenterDist', 'ID', within=['RunNumber'])\n",
    "res_sd = rm_sd.fit()\n",
    "print(res_sd.summary())\n",
    "\n",
    "# add significance markers to the plot\n",
    "tukey_center_sd_results = pairwise_tukeyhsd(std_center_data ['CenterDist'], std_center_data ['RunNumber'], alpha=0.05)\n",
    "tukey_center_sd_results = pd.DataFrame(data=tukey_center_sd_results._results_table.data[1:], columns=tukey_center_sd_results._results_table.data[0])\n",
    "tukey_center_sd_results = tukey_center_sd_results[tukey_center_sd_results['reject'] == True]\n",
    "# y_values = [std_dev['CenterDist'].max()*1.1, std_dev['CenterDist'].max()*1.2, std_dev['CenterDist'].max()*1.3]\n",
    "\n",
    "\n",
    "print(tukey_center_sd_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab8ff40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress, t, ttest_1samp\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_slope = df_concat.copy()\n",
    "\n",
    "# Calculate the slopes of the fitted lines for each participant\n",
    "slopes = []\n",
    "for participant in df_slope['ID'].unique():\n",
    "    estimation = df_slope.loc[df_slope['ID'] == participant, 'mainEstimate']\n",
    "    actual = df_slope.loc[df_slope['ID'] == participant, 'mainMeters']\n",
    "    slope, _, _, _, _ = linregress(estimation, actual)\n",
    "    slopes.append(slope)\n",
    "\n",
    "print (slopes)\n",
    "# Calculate the standard deviation of the slopes\n",
    "std_dev_slopes = np.std(slopes)\n",
    "\n",
    "# Calculate the confidence interval for the standard deviation\n",
    "n = len(slopes)\n",
    "t_value = t.ppf(0.975, n - 1)\n",
    "std_error = std_dev_slopes / np.sqrt(n)\n",
    "ci_low = std_dev_slopes - t_value * std_error\n",
    "ci_high = std_dev_slopes + t_value * std_error\n",
    "\n",
    "print(\"Standard deviation:\", std_dev_slopes)\n",
    "print(\"95% Confidence interval:\", (ci_low, ci_high))\n",
    "print('\\n')\n",
    "\n",
    "# Perform a one-sample t-test to determine if the standard deviation is significant\n",
    "t_stat, p_val = ttest_1samp(slopes, 0)\n",
    "\n",
    "print(p_val)\n",
    "print('\\n')\n",
    "\n",
    "if p_val < 0.05:\n",
    "    print(\"The variability in responses across subjects is statistically significant.\")\n",
    "else:\n",
    "    print(\"The variability in responses across subjects is not statistically significant.\")\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e6c832",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
